{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63049be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoEncoders import TopKSAE, JumpReLUSAE, ReLUSAE, OrthogonalSAE\n",
    "\n",
    "\n",
    "\n",
    "from Utils import createImageDataloader\n",
    "import clip\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9b3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/Users/mawy/Desktop/Square Dataset/imgs'\n",
    "W, H = 224, 224\n",
    "BATCH = 64\n",
    "\n",
    "loader = createImageDataloader(DATA_DIR, W, H, bsize=BATCH, shuffle=True)\n",
    "xb, _ = next(iter(loader))\n",
    "print(xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b85c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit, preprocess = clip.load('ViT-B/32', device=device)\n",
    "vit.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2760d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Bias initialized to Geometric Median\n"
     ]
    }
   ],
   "source": [
    "sae = ReLUSAE(d=512, n=128, lam=0.1)\n",
    "sae.findBias(vit, loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba66dd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/250 [00:15<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     feats \u001b[38;5;241m=\u001b[39m vit\u001b[38;5;241m.\u001b[39mvisual(xb)      \u001b[38;5;66;03m# [B, 768]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m recon, z \u001b[38;5;241m=\u001b[39m sae(feats)           \u001b[38;5;66;03m# recon: [B,768]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(recon, feats)\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(sae.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    sae.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}/{epochs}\", unit=\"batch\")\n",
    "\n",
    "    for xb, _ in pbar:\n",
    "        xb = xb.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats = vit.visual(xb)      # [B, 768]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon, z = sae(feats)           # recon: [B,768]\n",
    "        loss = criterion(recon, feats)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sae.renorm()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        pbar.set_postfix(batch_loss=loss.item(), avg_loss=(running_loss / ((pbar.n+1)*loader.batch_size)))\n",
    "\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{epochs} finished â€” Avg Reconstruction Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
